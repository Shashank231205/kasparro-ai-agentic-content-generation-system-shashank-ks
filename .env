# ============================
# MODEL CONFIG
# ============================

# Use FLAN fallback chain (no BART)
QUESTION_MODEL=google/flan-t5-large,google/flan-t5-base,google/flan-t5-small
GENERATION_MODEL=google/flan-t5-base

# ============================
# FILE PATHS
# ============================
INPUT_PRODUCT_DATA=input/product_data.json

TEMPLATE_FAQ=templates/faq_template.json
TEMPLATE_PRODUCT=templates/product_page_template.json
TEMPLATE_COMPARISON=templates/comparison_page_template.json

OUTPUT_FAQ=outputs/faq.json
OUTPUT_PRODUCT=outputs/product_page.json
OUTPUT_COMPARISON=outputs/comparison_page.json

# ============================
# LLM PARAMETERS
# ============================
MAX_TOKENS=256
TEMPERATURE=0.3
TOP_P=0.9
MIN_QUESTIONS=15

# ============================
# LOGGING
# ============================
LOG_LEVEL=INFO

# ============================
# FUTURE EXTENSIONS
# ============================
USE_REMOTE_LLM=false
