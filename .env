# ============================
# MODEL CONFIG
# ============================


# Use ONLY small FLAN for stability & speed
QUESTION_MODEL=mistralai/Mistral-7B-Instruct-v0.2-GPTQ
GENERATION_MODEL=mistralai/Mistral-7B-Instruct-v0.2-GPTQ


# ============================
# FILE PATHS
# ============================

INPUT_PRODUCT_DATA=input/product_data.json

TEMPLATE_FAQ=templates/faq_template.json
TEMPLATE_PRODUCT=templates/product_page_template.json
TEMPLATE_COMPARISON=templates/comparison_page_template.json

OUTPUT_FAQ=outputs/faq.json
OUTPUT_PRODUCT=outputs/product_page.json
OUTPUT_COMPARISON=outputs/comparison_page.json

# ============================
# LLM PARAMETERS
# ============================

MAX_TOKENS=256
TEMPERATURE=0.3
TOP_P=0.9
MIN_QUESTIONS=15

# ============================
# LOGGING
# ============================

LOG_LEVEL=INFO

# ============================
# FUTURE EXTENSIONS
# ============================

USE_REMOTE_LLM=false
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=kasparro-ai-agent
LANGCHAIN_VERBOSE=true
